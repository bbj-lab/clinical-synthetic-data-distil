{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "input_file=\"bool_num\"\n",
    "min_difficulty=1\n",
    "file_name = f\"synth_{input_file}_{min_difficulty}_df\"\n",
    "\n",
    "df = pd.read_csv(f\"../data/synthetic-raw/{file_name}.csv\", compression='gzip')\n",
    "display(df['question_type'].value_counts())\n",
    "print(df.shape)\n",
    "\n",
    "# balance df \n",
    "# df = df.iloc[:26415]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 50000\n",
    "# new_df = df.groupby('question_type').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n",
    "new_df = df.groupby('question_type').apply(lambda x: x.nlargest(min_count, 'difficulty')).reset_index(drop=True)\n",
    "display(new_df['question_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = f\"\"\"You are a clinical research assistant helping to accurately answer questions from clinical notes. You answer with a single valid JSON object based on the patient note. \n",
    "All dates have been shifted to keep data de-identified, so they may be in the future. We care only about information captured in the note, for example when asking what is the highest lab a patient has, we mean the highest lab recorded in the note. \n",
    "If you cannot find information to answer the question asked of you in the note answer Not Available, unless the rest of the prompt recommends something different. \n",
    "\"\"\"\n",
    "\n",
    "def create_prompt(note, question, qtype):\n",
    "    if qtype in ['yes', 'na-bool']:\n",
    "        type_str = \"str - 'Yes/No'\"\n",
    "        answer_str = \"str - 'Yes' or 'No' if the question can be answered based on the note, if the question cannot be answered based on the content of the note answer 'NA'\"\n",
    "        json_example = f\"\"\"```json\n",
    "{{\n",
    "    \"question\" : \"Does the note state that the patient is breathing normally on room air?\",\n",
    "    \"type\": \"Yes/No\",\n",
    "    \"answer\": \"No\",\n",
    "    \"section\": \"History of Present Illness\",    \n",
    "    \"source\": \"She currently is dependent on oxygen and wears 1.5-2 liters around the clock\",\n",
    "    \"explanation\": \"The note states that she relies on oxygen and provides the amount as 1.5-2 liters so she is not breathing room air. We can assume since she is receiving o2 supplmentation and dependent on it, she cannot breathe normally on room air.\"\n",
    "}}```\"\"\"\n",
    "        # \"difficulty\": \"2\",\n",
    "    elif qtype in ['numeric', 'na-numeric']:\n",
    "        type_str = \"str - 'Numeric'\"\n",
    "        answer_str = \"float - a single number (e.g., 92.5) or NA if the answer is not in the note\"\n",
    "        json_example = f\"\"\"```json\n",
    "{{\n",
    "    \"question\": \"What was the patient's highest creatinine measurement recorded in the note?\",\n",
    "    \"type\": \"Numeric\",\n",
    "    \"answer\": \"1.4\",\n",
    "    \"section\": \"Pertinent Results\",    \n",
    "    \"source\": \"12/03/2023: CREAT: 1.4 \\n 12/07/2023: CREAT: 1.1\",\n",
    "    \"explanation\": \"The highest CREAT measurement was 1.4 because 12/03/2023 is before 12/07/2023.\"\n",
    "}}```\"\"\"\n",
    "        # \"difficulty\": \"4\",\n",
    "    else:\n",
    "        print(qtype)\n",
    "        raise Exception('Not Implemented')\n",
    "\n",
    "    prompt = f\"\"\"***PATIENT NOTE:\n",
    "    {note}\n",
    "\n",
    "    Answer the following \n",
    "    *** QUESTION:\n",
    "    {question}\n",
    "\n",
    "    *** Format your response as a JSON object with the following keys: \n",
    "    * question: str - the question you were asked to answer\n",
    "    * type: {type_str}\n",
    "    * answer: {answer_str}\n",
    "    * section: str - the specific section of the note which contains the answer to the question (Example Answers: 'History of Present Illness', 'Past Medical History', 'Social History', 'Family History', 'Physical Exam', 'Pertinent Results', 'Brief Hospital Course', 'Discharge Medications', 'Discharge Disposition', 'Discharge Condition', 'Discharge Instructions')\n",
    "    * source: str - exact quote of content in the note that allowed you to answer the question, this should be a quote directly taken from the \"***PATIENT NOTE\". Copy and pasting this string should exactly match content in the Note.\n",
    "    * explanation: str - explanation of why the answer is correct and how the source in the note helped to answer the question\n",
    "    \n",
    "    An example of how your JSON response should be formatted is shown below (this is only an example of one question, others should be in a list, your answer should be based on the ***Patient Note provided above):\n",
    "    ***EXAMPLE RESPONSE:\n",
    "    {json_example}\n",
    "\n",
    "    Provide a response that can be directly read by the Python JSON Parser library based on the ***PATIENT NOTE at the beginning of this message.\n",
    "    \"\"\"\n",
    "    # * difficulty: int - a score from 1-10 indicating how difficult this question is to answer based on the note\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# string compatible isnan\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def format_output(r):\n",
    "    if isNaN(r['answer']):\n",
    "        answer = 'NA'\n",
    "    else:\n",
    "        answer = r['answer']\n",
    "    output_json = f\"\"\"```json\n",
    "{{\n",
    "    \"question\" : \"{r['question']}\",\n",
    "    \"type\": \"{r['question_type']}\",\n",
    "    \"answer\": \"{answer}\",\n",
    "    \"section\": \"{r['section']}\",\n",
    "    \"source\": \"{r['source']}\",\n",
    "    \"explanation\": \"{r['explanation']}\"\n",
    "}}```\"\"\"\n",
    "    return output_json\n",
    "\n",
    "\n",
    "examples = []\n",
    "for i, row in tqdm(new_df.iterrows(), total=new_df.shape[0]):\n",
    "    example_dict = {\n",
    "            'id': i,\n",
    "            'output': format_output(row),\n",
    "            'prompt': create_prompt(row['text'], row['question'], qtype=row['question_type'])\n",
    "        }\n",
    "\n",
    "    examples.append(example_dict)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "save_df = pd.DataFrame(examples)\n",
    "print(new_df.shape, save_df.shape)\n",
    "# Shuffle and split new_df\n",
    "new_train_df, new_test_df = train_test_split(new_df, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "# Ensure the same split and indices for save_df\n",
    "save_train_df = save_df.loc[new_train_df.index]\n",
    "save_test_df = save_df.loc[new_test_df.index]\n",
    "\n",
    "print(new_train_df.shape, new_test_df.shape)\n",
    "print(save_train_df.shape, save_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save\n",
    "from datasets import Dataset\n",
    "\n",
    "folder_path = \"../data/synthetic-raw\"\n",
    "\n",
    "train_file = f\"{folder_path}/train_{input_file}_{min_difficulty}-{min_count}-hardest.arrow\"\n",
    "test_file = f\"{folder_path}/test_{input_file}_{min_difficulty}-{min_count}-hardest.arrow\"\n",
    "\n",
    "\n",
    "save_train_ds = Dataset.from_pandas(save_train_df)\n",
    "save_test_ds = Dataset.from_pandas(save_test_df)\n",
    "\n",
    "save_train_ds.save_to_disk(train_file)\n",
    "save_test_ds.save_to_disk(test_file)\n",
    "\n",
    "new_train_df.to_csv(f\"{folder_path}/train_{input_file}_{min_difficulty}-{min_count}-hardest.csv\", index=False, compression='gzip')\n",
    "new_test_df.to_csv(f\"{folder_path}/test_{input_file}_{min_difficulty}-{min_count}-hardest.csv\", index=False, compression='gzip')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
