{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on all - binary, numeric, and na-numeric\n",
    "# train on all - binary only\n",
    "# train on all - binary and numeric\n",
    "# train on all - binary, numeric, and na-numeric, na-bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = './outputs/100000/Meta-Llama-3.1-70B-Instruct/'\n",
    "folder_path = '../synthetic_output/100000'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load CSV files from a folder and add a 'question_type' column\n",
    "def load_csv_with_question_type(folder_path):\n",
    "    # Initialize an empty DataFrame to store all data\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file is a CSV file\n",
    "        if file_name.endswith('.csv'):\n",
    "            # Get the question_type from the file name (text prior to the first underscore)\n",
    "            # question_type = file_name.split('_')[0]\n",
    "\n",
    "            # Load the CSV file into a DataFrame\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            question_type = file_path.split('/')[-1].split('_')[1]\n",
    "            # Add the 'question_type' column\n",
    "            df['question_type'] = question_type\n",
    "\n",
    "            # Append the data to the all_data DataFrame\n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv_with_question_type(folder_path)\n",
    "print(df[df['question_type']=='yes'].shape, df[df['question_type']=='numeric'].shape)\n",
    "print('cur shape', df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_attributes(df, column_name):\n",
    "    results = []\n",
    "    failure_list = []\n",
    "    \n",
    "    def clean_text(text):\n",
    "        \"\"\" Clean the text to improve JSON parsing \"\"\"\n",
    "        # Remove the code block markers and extra new lines\n",
    "        text = re.sub(r'```json', '', text, flags=re.DOTALL)\n",
    "        text = re.sub(r'```', '', text, flags=re.DOTALL)\n",
    "        text = re.sub(r'\\n+', ' ', text, flags=re.DOTALL)\n",
    "        \n",
    "        # Find the JSON list part in the text\n",
    "        json_start = text.find('[')\n",
    "        json_end = text.rfind(']')\n",
    "        \n",
    "        if json_start == -1 or json_end == -1:\n",
    "            return None\n",
    "        \n",
    "        json_text = text[json_start:json_end + 1]\n",
    "        \n",
    "        return json_text\n",
    "    \n",
    "    def extract_from_json_like(text):\n",
    "        cleaned_text = clean_text(text)\n",
    "        if not cleaned_text:\n",
    "            return None\n",
    "        try:\n",
    "            data = json.loads(cleaned_text)\n",
    "            return data\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            return None\n",
    "\n",
    "    def extract_from_regex(text):\n",
    "        pattern = re.compile(\n",
    "            r'{\"question\":\\s*\"(?P<question>.*?)\",\\s*\"type\":\\s*\"(?P<type>.*?)\",\\s*\"answer\":\\s*\"(?P<answer>.*?)\",\\s*\"section\":\\s*\"(?P<section>.*?)\",\\s*\"source\":\\s*\"(?P<source>.*?)\",\\s*\"explanation\":\\s*\"(?P<explanation>.*?)\",\\s*\"difficulty\":\\s*\"(?P<difficulty>.*?)\"}',\n",
    "            re.DOTALL\n",
    "        )\n",
    "        return [match.groupdict() for match in pattern.finditer(text)]\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row[column_name]\n",
    "        subject_id = row['subject_id']\n",
    "        hadm_id = row['hadm_id']\n",
    "        question_type = row['question_type']\n",
    "        \n",
    "        if pd.isnull(text) or not isinstance(text, str):\n",
    "            failure_list.append(f\"{idx} Blank - {text}\")\n",
    "            continue\n",
    "        \n",
    "        extracted_data = extract_from_json_like(text)\n",
    "        if not extracted_data:\n",
    "            extracted_data = extract_from_regex(text)\n",
    "        \n",
    "        if not extracted_data:\n",
    "            failure_list.append(f\"{idx} Extraction Failed - {text}\")\n",
    "        else:\n",
    "            for item in extracted_data:\n",
    "                try:\n",
    "                    item.update({\n",
    "                        'subject_id': subject_id,\n",
    "                        'hadm_id': hadm_id,\n",
    "                        'question_type': question_type,\n",
    "                        'llm_response': text\n",
    "                    })\n",
    "                    results.append(item)\n",
    "                except Exception as e:\n",
    "                    failure_list.append(f\"{idx} Data Update Failed - {str(e)} - {text}\")\n",
    "    \n",
    "    result_df = pd.DataFrame(results, columns=['subject_id', 'hadm_id', 'question_type', 'llm_response', 'question', 'type', 'answer', 'section', 'source', 'explanation', 'difficulty'])\n",
    "    return result_df, failure_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_num_result_df, na_num_failures = extract_attributes(df[df['question_type']=='na-numeric'], 'output')\n",
    "yes_result_df, yes_failures = extract_attributes(df[df['question_type']=='yes'], 'output')\n",
    "numeric_result_df, numeric_failures = extract_attributes(df[df['question_type']=='numeric'], 'output')\n",
    "na_bool_result_df, na_bool_failures = extract_attributes(df[df['question_type']=='na-bool'], 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(na_num_failures), len(yes_failures), len(numeric_failures), len(na_bool_failures))\n",
    "print(na_num_result_df.shape, yes_result_df.shape, numeric_result_df.shape, na_bool_result_df.shape)\n",
    "\n",
    "# 26 97 323 18\n",
    "# (106245, 10) (212133, 10) (209705, 10) (106288, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_num_result_df['difficulty'] = pd.to_numeric(na_num_result_df['difficulty'], errors='coerce')\n",
    "na_bool_result_df['difficulty'] = pd.to_numeric(na_bool_result_df['difficulty'], errors='coerce')\n",
    "numeric_result_df['difficulty'] = pd.to_numeric(numeric_result_df['difficulty'], errors='coerce')\n",
    "yes_result_df['difficulty'] = pd.to_numeric(yes_result_df['difficulty'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('na-num')\n",
    "display(na_num_result_df['difficulty'].value_counts())\n",
    "print('na-bool')\n",
    "display(na_bool_result_df['difficulty'].value_counts())\n",
    "print('numeric')\n",
    "display(numeric_result_df['difficulty'].value_counts())\n",
    "print('bool')\n",
    "display(yes_result_df['difficulty'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(na_num_result_df['question_type'].value_counts())\n",
    "display(na_bool_result_df['question_type'].value_counts())\n",
    "display(numeric_result_df['question_type'].value_counts())\n",
    "display(yes_result_df['question_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([numeric_result_df, yes_result_df, na_num_result_df, na_bool_result_df])\n",
    "full_df.sort_values(['subject_id', 'hadm_id'])\n",
    "\n",
    "print(full_df.shape)\n",
    "notes_df = pd.read_csv('../data/mimic/notes_100000.csv', compression='gzip')\n",
    "full_df = full_df[['subject_id', 'hadm_id', 'question_type', 'question',\n",
    "                   'type', 'answer', 'section', 'source', 'explanation', 'difficulty']].merge(notes_df, how='left', on=['subject_id', 'hadm_id'])\n",
    "print(full_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['difficulty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (9, 0, -1):\n",
    "    print(i)\n",
    "    save_df = full_df.loc[full_df['difficulty'] >= i]\n",
    "    print(save_df.shape)\n",
    "    save_df.to_csv(f\"../data/synthetic-raw/synth_all_{i}_df.csv\", index=False, compression='gzip')\n",
    "\n",
    "for i in range (9, 0, -1):\n",
    "    print(i)\n",
    "    save_df = full_df.loc[(full_df['difficulty'] >= i) & (full_df['question_type'].isin(['yes']))]\n",
    "    print(save_df.shape)\n",
    "    save_df.to_csv(f\"../data/synthetic-raw/synth_bool_{i}_df.csv\", index=False, compression='gzip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (9, 0, -1):\n",
    "    print(i)\n",
    "    save_df = full_df.loc[(full_df['difficulty'] >= i) & (full_df['question_type'].isin(['yes', 'numeric']))]\n",
    "    print(save_df.shape)\n",
    "    save_df.to_csv(f\"../data/synthetic-raw/synth_bool_num_{i}_df.csv\", index=False, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('../data/synthetic-raw/synth_all_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
